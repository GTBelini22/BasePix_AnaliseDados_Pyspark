{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Case Final\n",
        "## Análise de Transações PIX\n",
        "CRISP-DM - https://www.escoladnc.com.br/blog/data-science/metodologia-crisp-dm/\n",
        "### Objetivos\n",
        "- Limpar e pré-processar os dados das transações PIX\n",
        "- Analisar padrões de uso do PIX, tais como os canais mais utilizados e os valores de transação mais comuns\n",
        "- Use o PySpark MLlib para treinar e avaliar um modelo de detecção de fraude\n",
        "- Avaliar o desempenho do modelo e fazer recomendações para melhorias futuras\n",
        "\n",
        "### Dados\n",
        "\n",
        "O conjunto de dados inclui as seguintes informações para cada transação:\n",
        "- Detalhes da transação: valor, tempo, remetente e receptor CPF/CNPJ, tipo\n",
        "- Etiqueta de fraude: uma variável binária que indica se a transação foi fraudulenta (1) ou não (0)\n",
        "\n",
        "### Tarefas\n",
        "- Normalização dos dados:\n",
        "  - O dataset que você lerá está em formato json.\n",
        "  ```json\n",
        "  {\n",
        "      \"id_transacao\": inteiro,\n",
        "      \"valor\": texto,\n",
        "      \"remetente\": {\n",
        "          \"nome\": texto,\n",
        "          \"banco\": texto,\n",
        "          \"tipo\": texto\n",
        "      },\n",
        "      \"destinatario\": {\n",
        "          \"nome\": texto,\n",
        "          \"banco\":texto,\n",
        "          \"tipo\": texto\n",
        "      },          \n",
        "      \"categoria\":texto,\n",
        "      \"chave_pix\":texto,\n",
        "      \"transaction_date\":texto,\n",
        "      \"fraude\":inteiro,\n",
        "  }\n",
        "    ```\n",
        "  - Faça sua transformação para formato colunar\n",
        "- Análise Exploratória de Dados: Use o PySpark para analisar padrões de uso do PIX:\n",
        "  - chaves pix mais usadas;\n",
        "  - os valores de transação mais comuns;\n",
        "  - distribuição dos valores de transação por hora e dia;\n",
        "  - quais bancos receberam mais transferências por dia;\n",
        "  - para qual tipo de pessoa (PF ou PJ) foram realizadas mais transações\n",
        "- Engenharia de Recursos: Apresentar novas características que podem ser úteis para a detecção de fraudes, tais como o número de transações feitas pelo mesmo remetente em um período de tempo específico.\n",
        "- Modelagem: Use o PySpark MLlib para treinar e detectar possíveis transações que contenham fraude.\n",
        "\n",
        "### Observação\n",
        "É importante notar que este é um caso simplificado, e em cenários do mundo real você teria que lidar com dados mais complexos, usar técnicas mais avançadas como métodos de conjuntos e considerar o conhecimento de domínio, bem como leis e regulamentos das instituições financeiras no Brasil.\n",
        "\n",
        "\n",
        "### Observação II\n",
        "Não existe resposta 100% correta. É necessário que você use seu pensamento crítico para definir as melhores métricas e análises para o caso."
      ],
      "metadata": {
        "id": "CUrfUdhmyVpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entendimento do Negócio\n",
        "Você trabalha em um banco e o principal meio de pagamento utilizado no seu banco é o Pix.\n",
        "\n",
        "Através da base de transações do pix o banco deseja entender qual é o perfil dos clientes que utilizam o pix, além de verificar possíveis transações que tenham fraude. Porém, eles tem um cliente específico que tem um relacionamento muito bom para o banco, por isso, você recebeu a base de transações de cliente dos últimos 2 anos e precisa a partir dela criar um relatório contendo as principais características das transações.\n",
        "\n",
        "\n",
        "Então, resumindo, temos dois principais objetivos para esse case:\n",
        "1. Obter valor a partir dos dados\n",
        "  - Para qual banco esse cliente mais transfere?\n",
        "  - Qual é a média de transferências por período que esse cliente faz?\n",
        "  - Baseando-se no valor das transferências, poderia dar um aumento de crédito?\n",
        "  - Para o que esse cliente mais usa as transferências?\n",
        "2. Executar um algoritmo de machine learning que identifique possíveis transações com fraude.\n",
        "3. Pós Processamento\n",
        "  - Defina ao mínimo cinco métricas de qualidade para seus dados\n",
        "  - Explique se os seus dados estão com uma boa qualidade"
      ],
      "metadata": {
        "id": "1qEUukChAJ1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-TJyZL_iM9a",
        "outputId": "2b5a37fd-8e92-4c0c-c962-d4b2f12d88eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação do Ambiente de Desenvolvimento"
      ],
      "metadata": {
        "id": "fpXPtmLKKxnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar a última versão do PySpark\n",
        "!pip install pyspark #==3.3.1\n",
        "\n",
        "# Instalar o NGROK\n",
        "!wget -qnc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -n -q ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# Autenticar a sessão do SparkUI com NGROK\n",
        "!./ngrok authtoken 2KBeQEmmd1YNlQ86GGKf3KFOkb3_6sQH7JEnvEhDxwn9A7WnT\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!sleep 10\n",
        "!curl -s http://localhost:4040/api/tunnels | grep -Po 'public_url\":\"(?=https)\\K[^\"]*'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG5nQf1-rMJU",
        "outputId": "acb48e32-8213-40ab-99c7-1cc5b0f1b54c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=7c1c83f5853df896917f41e2ac85ff7e118ee4dd32742a69cdbaf50c33d65763\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Undesrtanting\n",
        "\n",
        "Primeiramente, devemos entender tudo sobre a fonte dos dados\n",
        "- Como o dado chega até nós?\n",
        "- Qual formato virá?\n",
        "- Aonde o processamento será executado (AWS EMR, Cluster On-Premise)?\n",
        "- De quanto em quanto tempo eu preciso gerar esse relatório (mensal, diário, near-real time)?\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"id_transacao\": inteiro,\n",
        "  \"valor\": texto,\n",
        "  \"remetente\": {\n",
        "      \"nome\": texto,\n",
        "      \"banco\": texto,\n",
        "      \"tipo\": texto\n",
        "  },\n",
        "  \"destinatario\": {\n",
        "      \"nome\": texto,\n",
        "      \"banco\":texto,\n",
        "      \"tipo\": texto\n",
        "  },\n",
        "  \"categoria\": texto,\n",
        "  \"transaction_date\":texto,\n",
        "  \"chave_pix\":texto,\n",
        "  \"fraude\":inteiro,\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "NFBKW-UUAMOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação dos Dados\n",
        "Agora é hora de começar a preparar os dados de acordo com as suas necessidades."
      ],
      "metadata": {
        "id": "KPvcwRICAPod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciar a sessão spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "      .config('spark.ui.port', '4050')\n",
        "      .appName(\"CaseFinal\")\n",
        "      .getOrCreate()\n",
        ")\n"
      ],
      "metadata": {
        "id": "1nM-CJzUrcJa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "\n",
        "schema_remetente_destinatario = StructType([\n",
        "    StructField('nome', StringType()),\n",
        "    StructField('banco', StringType()),\n",
        "    StructField('tipo', StringType())\n",
        "])\n",
        "\n",
        "\n",
        "schema_base_pix = StructType([\n",
        "    StructField('id_transacao', IntegerType()),\n",
        "    StructField('valor', DoubleType()),\n",
        "    StructField('remetente', schema_remetente_destinatario),\n",
        "    StructField('destinatario', schema_remetente_destinatario),\n",
        "    StructField('chave_pix', StringType()),\n",
        "    StructField('categoria', StringType()),\n",
        "    StructField('transaction_date', StringType()),\n",
        "    StructField('fraude', IntegerType())\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = spark.read.json('/content/drive/MyDrive/Colab Notebooks/Big data/Case final/Aula 26/case_final.json', schema= schema_base_pix, timestampFormat= 'yyyy-MM-dd HH:mm:ss')"
      ],
      "metadata": {
        "id": "dMnT7qCotCAe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "Z5zRZxdeuPR0",
        "outputId": "0871af46-ef09-45b1-ee08-ee6354f59a09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id_transacao: integer (nullable = true)\n",
            " |-- valor: double (nullable = true)\n",
            " |-- remetente: struct (nullable = true)\n",
            " |    |-- nome: string (nullable = true)\n",
            " |    |-- banco: string (nullable = true)\n",
            " |    |-- tipo: string (nullable = true)\n",
            " |-- destinatario: struct (nullable = true)\n",
            " |    |-- nome: string (nullable = true)\n",
            " |    |-- banco: string (nullable = true)\n",
            " |    |-- tipo: string (nullable = true)\n",
            " |-- chave_pix: string (nullable = true)\n",
            " |-- categoria: string (nullable = true)\n",
            " |-- transaction_date: string (nullable = true)\n",
            " |-- fraude: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem\n",
        "Aqui você encontrará utilidade para os dados levantados.\n",
        "\n",
        "Aqui será onde teremos insights e, a partir desses, novos conhecimentos sobre o business (se tudo até aqui foi feito corretamente).\n",
        "\n",
        "\n",
        "- Para qual banco esse cliente mais transfere?\n",
        "- Qual é a média de transferências por período que esse cliente faz?\n",
        "- Baseando-se no valor das transferências, poderia dar um aumento de crédito?\n",
        "- Para o que esse cliente mais usa as transferências?\n",
        "- Executar um algoritmo de machine learning que identifique possíveis transações com fraude.\n"
      ],
      "metadata": {
        "id": "tnOJ5pwHARTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de Predição de Fraudes"
      ],
      "metadata": {
        "id": "rIVX81NQzsoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação do Modelo\n",
        "Será que seu modelo atinge todas as necessidades que foram definidas inicialmente? (e.g. pessoa em cima da bicicleta muda o resultado final)\n",
        "\n"
      ],
      "metadata": {
        "id": "2zHoQJWtATfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment\n",
        "Apresente o relatório com os resultados obtidos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "JOTAB1JSAVPi"
      }
    }
  ]
}